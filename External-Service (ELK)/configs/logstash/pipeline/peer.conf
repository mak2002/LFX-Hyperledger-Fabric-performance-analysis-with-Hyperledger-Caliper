input {
  pipeline {
    address => peerLogs
  }
}

filter {
  mutate {
    add_field => {
      "peerTestField" => "peerTestFieldValue"
    }
  }

  if [fabric_log_message] =~ /.+ Validated block .+/ {
      grok {
         match => {
            "fabric_log_message" => "%{TIMESTAMP_ISO8601:log_timestamp} %{GREEDYDATA} \[%{WORD:channel_name}\] Validated block \[%{NUMBER:block_number:int}\] in %{NUMBER:processing_time}ms"
         }
         tag_on_failure => ["_orderer-blockinfo-extract-failure", "_log-error"]
      }

      if "_orderer-blockinfo-extract-failure" not in [tags] {
         mutate {
            add_field => {
               "[block_info][block_number]" => "%{block_number}"
               "[block_info][channel_name]" => "%{channel_name}"
               "[block_info][processing_time]" => "%{processing_time}"
               "[block_info][block_timestamp]" => "%{log_timestamp}"
            }
         }
         mutate {
            remove_field => ["block_number", "channel_name", "processing_time", "log_timestamp"]
         }  
      }
  } 
  else if [fabric_log_message] =~ /.+ Committed block .+/ {
      grok {
         match => {
            "fabric_log_message" => "%{TIMESTAMP_ISO8601:log_timestamp} %{GREEDYDATA} \[%{WORD:channel_name}\] Committed block \[%{NUMBER:block_number:int}\] with %{NUMBER:transaction_count} transaction\(s\) in %{NUMBER:commit_time}ms \(state_validation=%{NUMBER:state_validation_time}ms block_and_pvtdata_commit=%{NUMBER:block_and_pvtdata_commit_time}ms state_commit=%{NUMBER:state_commit_time}ms\) commitHash=\[%{DATA:commit_hash}\]"
         }
         tag_on_failure => ["_orderer-blockinfo-extract-failure", "_log-error"]
      }

      if "_orderer-blockinfo-extract-failure" not in [tags] {
         mutate  {
            add_field => {
               "[block_info][block_number]" => "%{block_number}"
               "[block_info][channel_name]" => "%{channel_name}"
               "[block_info][transaction_count]" => "%{transaction_count}"
               "[block_info][block_timestamp]" => "%{log_timestamp}"
               "[block_info][commit_time]" => "%{commit_time}"
               "[block_info][state_validation_time]" => "%{state_validation_time}"
               "[block_info][block_and_pvtdata_commit_time]" => "%{block_and_pvtdata_commit_time}"
               "[block_info][state_commit_time]" => "%{state_commit_time}"
               "[block_info][commit_hash]" => "%{commit_hash}"
            }
            remove_field => ["block_number", "channel_name", "transaction_count", "commit_time", "state_validation_time", "block_and_pvtdata_commit_time", "state_commit_time", "log_timestamp", "commit_hash"]
         }
      } 
  }
   else if [fabric_log_message] =~ /.+ Received block .+/ {
      grok {
         match => {
            # 2023-09-30 17:23:16.314 UTC 09f8 INFO [gossip.privdata] StoreBlock -> Received block [457] from buffer channel=mychannel
            "fabric_log_message" => "%{TIMESTAMP_ISO8601:log_timestamp} %{GREEDYDATA} \[%{DATA:log_source}\] %{WORD:log_event} -> Received block \[%{NUMBER:block_number:int}\] from buffer channel=%{WORD:received_channel}"
         }
         tag_on_failure => ["_orderer-blockinfo-extract-failure", "_log-error"]
      }

      if "_orderer-blockinfo-extract-failure" not in [tags] {
         mutate {
            add_field => {
               "[block_info][log_timestamp]" => "%{log_timestamp}"
               "[block_info][log_event]" => "%{log_event}"
               "[block_info][block_number]" => "%{block_number}"
               "[block_info][received_channel]" => "%{received_channel}"
            }
            remove_field => ["log_timestamp", "channel_name", "log_level", "log_source", "log_event", "block_number", "received_channel"]
         }
      }
   }
}

output {
  # elasticsearch {
  #   hosts => ["elasticsearch:9200"]
  #   ssl => false
  #   ssl_certificate_verification => false
  #   sniffing => true
  #   index => "test-%{+YYYY.MM.dd}"
  # }
  file {
    path => "/usr/share/logstash/mylogs.log"
  }
}
